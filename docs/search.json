[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to My Data Science Portfolio",
    "section": "",
    "text": "Welcome to my data science portfolio! This site shows my journey learning data science and analytics. Here you’ll find projects that demonstrate what I’ve learned and discovered.\n\n\nThis portfolio shows my work learning data science. Each project includes:\n\nMy code with documentation\nVisualizations I created\nWhat I learned and discovered\n\nI built this site using Quarto and host it on GitHub Pages.\n\n\n\n\nProgramming: Python, Pandas for data analysis\nVisualization: Creating charts with Matplotlib and Seaborn\nData Collection: Getting data from files, websites, and APIs\nAnalysis: Finding patterns and answering questions with data\n\n\n\n\n\n\n\nLearn how I explore datasets to find interesting patterns and answer questions.\n\n\n\nSee how I gather data from different sources and prepare it for analysis.\n\n\n\nSee how I tackle a data science project beginning to end.\n\n\n\nThanks for visiting! Feel free to explore my projects and see what I’m learning."
  },
  {
    "objectID": "index.html#about-this-portfolio",
    "href": "index.html#about-this-portfolio",
    "title": "Welcome to My Data Science Portfolio",
    "section": "",
    "text": "This portfolio shows my work learning data science. Each project includes:\n\nMy code with documentation\nVisualizations I created\nWhat I learned and discovered\n\nI built this site using Quarto and host it on GitHub Pages."
  },
  {
    "objectID": "index.html#skills-im-learning",
    "href": "index.html#skills-im-learning",
    "title": "Welcome to My Data Science Portfolio",
    "section": "",
    "text": "Programming: Python, Pandas for data analysis\nVisualization: Creating charts with Matplotlib and Seaborn\nData Collection: Getting data from files, websites, and APIs\nAnalysis: Finding patterns and answering questions with data"
  },
  {
    "objectID": "index.html#my-projects",
    "href": "index.html#my-projects",
    "title": "Welcome to My Data Science Portfolio",
    "section": "",
    "text": "Learn how I explore datasets to find interesting patterns and answer questions.\n\n\n\nSee how I gather data from different sources and prepare it for analysis.\n\n\n\nSee how I tackle a data science project beginning to end.\n\n\n\nThanks for visiting! Feel free to explore my projects and see what I’m learning."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Analyzing Employee Attrition Data: A Step-by-Step Python Guide with Pandas and Matplotlib",
    "section": "",
    "text": "Introduction\nIn this tutorial you will learn how to locate a practice employee data set, load it, clean it, analyze it, and visualize it. Employee attrition is an important metric in the HR workd that represents how often people are leaving the company for any reason. The process outlined below will guide us on our search for deeper attrition insights.\n\n\n\nStep 1. Collecting and Loading Data\nCollecting data is an important first step in using data science principles to analyze a business problem. Large data quantity and high data quality are great goals to strive for when collecting data to produce the best results after analysis. For the purposes of this tutorial I will be selecting a dataset from Kaggle.com, a popular platform in the data science community, to show my analysis process end-to-end.\nThe dataset I chose contains fictitious data on terminations over ten years, showing both employees that are active and those that terminated. There are 18 columns or attributes we can work with including: employee age, employee tenure, employee number, employee status, departure reason, etc. I downloaded it into my project folder as MFG10YearTerminationData.csv and opened it within VS Code (my preferred IDE, although any will work).\nLet’s import pandas as pd and from matplotlib import pyplot as plt in our main file to get started, and use pd.read_csv() read our CSV into a DataFrame by running the code below.\n\n\nGetting Started\nimport pandas as pd\nfrom matplotlib import pyplot as plt\n\nattrit_df = pd.read_csv(\"MFG10YearTerminationData.csv\")\n\n\nCheck to make sure your data was read in correctly by using some quick summarization commands like .head(), .describe(), or .info() to get a general view of your data and perform some preliminary validation before analysis. These commands will return the first X rows of data, give general statistics about the “age” column, and give a concise description of the data frame respectively. I chose .describe() to check if the numbers seemed off or not at first glance.\n\n\nQuick Spot Check\nattrit_df[\"age\"].describe()\n\n\ncount    49653.000000\nmean        42.077035\nstd         12.427257\nmin         19.000000\n25%         31.000000\n50%         42.000000\n75%         53.000000\nmax         65.000000\nName: age, dtype: float64\n\n\nNow that we have checked that our data is collected and properly loaded, we can move into preparing it.\n\n\n\nStep 2. Preparing Data\nGetting the data ready to be analyzed is almost as important as the analysis itself! Working with incorrect or incomplete data can render any insights practically useless, so it’s important to take time to ensure your data is ready to be manipulated before jumping in. While every data set is different, it is always good to identify attributes/column of interest, clarify column names, drop duplicate rows, and identify missing/incorrect data. Below are several examples of how to evaluate the quality of your data.\nUsing commands like .strip, .lower, and .replace can help us create more uniform column names. pd.to_datetime converts the dates to the correct data type to ensure they work properly. The last line creates a new column returning True or False if the employee has been terminated, and converts those booleans into a binary column using .astype(int) that will help us calculate attrition later.\n\n\nData Preparation\nattrit_df.columns = [c.strip().lower().replace(\" \", \"_\") for c in attrit_df.columns]\n\nattrit_df[\"terminationdate_key\"] = pd.to_datetime(attrit_df.get(\"terminationdate_key\"), errors=\"coerce\")\n\nattrit_df[\"orighiredate_key\"] = pd.to_datetime(attrit_df.get(\"orighiredate_key\"), errors=\"coerce\")\n\nattrit_df = attrit_df.drop_duplicates()\n\nattrit_df[\"status\"] = attrit_df[\"status\"].str.strip().str.title()\n\nattrit_df[\"is_terminated\"] = (attrit_df[\"status\"] == \"Terminated\").astype(int)\n\n\nNow that we are confident our data is loaded correclty, our columns are uniform, and we dropped ny duplicates, we can get into analyzing the data!\n\n\n\nStep 3. Analyzing Data\nWhen analyzing data, it is important to start with questions that you would like to answer. Perhaps you already have some suspicion that a particular department is driving attrition ir a certain age group. These are perfect places to start, but don’t stop there! Consider alternative options and seek to prove/disprove your hypotheses with data.\n\n3.1 What is the overall attrition rate?\nWe can do a simple overall attrition calculation by counting all of the rows of data containing terminated employees and dividing that by the total number of rows in our data set. Using .mean() will quickly do this. I then printed the number and converted it into a percentage.\n\n\nCalculate Overall Attrition\noverall_rate = attrit_df[\"is_terminated\"].mean()\nprint(f\"The overall attrition rate is {round(overall_rate, 4)} or {round(overall_rate*100, 2)}%. That's nearly 3%!\")\n\n\nThe overall attrition rate is 0.0299 or 2.99%. That's nearly 3%!\n\n\n\n\n3.2 Do other apartments attrit more than others?\nAgain we can use .mean() to calculate the attrition percent, but this time we will group the percentages by department using .groupby().\n\n\nCalculate Attrition by Department\ndept_rate = attrit_df.groupby(\"department_name\")[\"is_terminated\"].mean().sort_values(ascending=False)\ndept_rate.head(10)\n\n\ndepartment_name\nInformation Technology    0.250000\nLegal                     0.176471\nLabor Relations           0.176471\nTraining                  0.166667\nAudit                     0.166667\nCompensation              0.166667\nInvestment                0.166667\nHR Technology             0.140625\nEmployee Records          0.136364\nAccounts Receiveable      0.128205\nName: is_terminated, dtype: float64\n\n\n\n\n3.3 Does tenure relate to attrition?\nHere we are looking at Tenure and Attrition to see if we can find any insights there. We created bins and labels and then used them with the .cut() function to look at tenure (a continuous variable) as if it were discrete.\n\n\nCalculate Attrition by Tenure\nbins = [0,1,3,5,10,20,60]\nlabels = [\"&lt;1\",\"1-3\",\"3-5\",\"5-10\",\"10-20\",\"20+\"]\nattrit_df[\"tenure_band\"] = pd.cut(attrit_df[\"length_of_service\"], bins=bins, labels=labels, right=False)\n\ntenure_rate = attrit_df.groupby(\"tenure_band\")[\"is_terminated\"].mean()\ntenure_rate\n\n\ntenure_band\n&lt;1       0.015800\n1-3      0.037508\n3-5      0.010812\n5-10     0.031268\n10-20    0.029859\n20+      0.044800\nName: is_terminated, dtype: float64\n\n\n\n\n3.4 How old are those who attrit?\nAgain, we are using the .cut() to look into another angle. This time is age and attrition.\n\n\nCalculate Attrition by Age\nage_bins = [16,25,35,45,55,65,100]\nage_labels = [\"16-24\",\"25-34\",\"35-44\",\"45-54\",\"55-64\",\"65+\"]\nattrit_df[\"age_band\"] = pd.cut(attrit_df[\"age\"], bins=age_bins, labels=age_labels, right=False)\n\nage_rate = attrit_df.groupby(\"age_band\")[\"is_terminated\"].mean()\nage_rate\n\n\nage_band\n16-24    0.043321\n25-34    0.016727\n35-44    0.008408\n45-54    0.005588\n55-64    0.036559\n65+      0.996627\nName: is_terminated, dtype: float64\n\n\n\n\n\n\nStep 4. Visualizing Data\nNow that we understand how to calculate attrition from a few different angles, now we can move into visualizing our findings in bar plots with pyplot from matplotlib. Since we imported pyplot as plt, we can use it with other commands like .figure(), .plot(), .title, and .show() to create data visualizations.\nSometimes visualizing data this way can make it easier to spot trends in the data rather than just reading it. All of the visualizations below use the data above to look at attrition from various angles like department, tenure, and age. Open the code chucnks to see what code is run to output the visualization.\n\n4.1 Attrition by department (bar)\n\n\nAttrition by Dept Bar Chart\nplt.figure()\ndept_rate.plot(kind=\"bar\")\nplt.title(\"Attrition Rate by Department\")\nplt.ylabel(\"Attrition Rate\")\nplt.xlabel(\"Department\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n4.2 Attrition by tenure band (bar)\n\n\nAttrition by Tenure Bar Chart\nplt.figure()\ntenure_rate.plot(kind=\"bar\")\nplt.title(\"Attrition Rate by Tenure Band\")\nplt.ylabel(\"Attrition Rate\")\nplt.xlabel(\"Tenure Band (years)\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n4.3 Attrition by age band (bar)\n\n\nAttrition by Age Bar Chart\nplt.figure()\nage_rate.plot(kind=\"bar\")\nplt.title(\"Attrition Rate by Age Band\")\nplt.ylabel(\"Attrition Rate\")\nplt.xlabel(\"Age Band\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\nStep 5. Storytelling With Data\nData driven insights are only as compellingas the story they tell. Communicating technical insights to non-techincal audiences is a skill developed overtime. Try to ask yourself, “What do these numbers mean for the company?” or “What actions should be taken as a result of these findings?”. Analyzing the data is important, but communicating what it means is perhaps even more important.\n\nWhat we found:\n\nAttrition is 3% overall. It’s highest in the IT department by far\nRates peak in the 1–3 and 20+ tenure bands, suggesting early and late stage retention as a problem\nAge bands 65+ show elevated rates, which may reflect retirement departures or possible age discrimination if the attrition is involuntary\n\nAs you can see, following these simple data science steps to load, prepare, and analyze data revealed trends that would be impossible to see when looking at the raw data. Even further, the bar chart visualizations we created made the hotspots in the data even easier to spot and supported our initial findings. Great job!\n\n\n\n\nCall to Action:\nVisit this site and find an employee dataset that interests you! Follow the steps above to calculate and visualize attrition. Have fun!! Here is a smiley face for you."
  }
]